# ğŸš€ ETL Mini Pipeline â€“ Python

This project implements a simple **ETL (Extract â†’ Transform â†’ Load)** pipeline using Python and pandas.

## ğŸ›  Tech Stack
- Python (Colab)
- pandas
- SQLite
- CSV

## ğŸ”„ ETL Steps

### 1ï¸âƒ£ Extract
- Loaded raw Kaggle dataset (CSV)
- Stored in `raw/` folder

### 2ï¸âƒ£ Transform
- Removed missing values and duplicates
- Standardized column names and data types
- Created derived columns (e.g., profit_margin, segment_flag)
- Validated row counts before & after cleaning

### 3ï¸âƒ£ Load
- Exported cleaned data to `processed_data.csv`
- Split into customers/orders/products outputs
- Loaded final data into `database.sqlite`

## ğŸ“‚ Project Files
- `task14_etl.ipynb`
- `processed_data.csv`
- `database.sqlite`

## ğŸ¯ Objective
To demonstrate a real-world ETL workflow using Python and SQLite for data engineering practice.
